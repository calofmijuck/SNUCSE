\documentclass{article}
\usepackage{kotex}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{geometry}
	\geometry{
		top = 30mm,
		left =30mm,
		right = 30mm,
		}
		
\pagenumbering{gobble}
\renewcommand{\baselinestretch}{1.3}
\newcommand*{\qed}{\hfill\ensuremath{\square}}%
\newcommand*{\tab}{\hspace*{5mm}}%
\newcommand*{\pr}{\mathrm{P}}%
\newcommand*{\ex}{\mathrm{\mathbf{E}}}%
\newcommand*{\var}{\mathrm{\mathbf{V}}}%

\begin{document}
\begin{center}
\textbf{\Large Discrete Mathematics Homework \#5}
\end{center}
\begin{flushright}
{\large 2017-18570 이성찬}\\
\end{flushright}

* Let $\pr(E)$ : probability of event $E$ and let $\ex(X)$ : expectaion of a random variable $X$.
\begin{itemize}
\item[\large \textbf{7.1.38}] Let H, T denote heads and tails, respectively. Also note that for the sample space $S$, $\left|S\right| = 8$, and each element of the sample space have equally likely outcomes.
	\begin{itemize}
		\item[\textbf{(a)}] $E_1=\{\text{THH, THT, TTH, TTT}\}$, and $E_2=\{\text{HHH, HHT, THH, THT}\}$. Thus $\pr(E_1) = \pr(E_2) = 4/8 = 1/2$. And since $E_1 \cap E_2 = \{\text{THH, THT}\}$, $\pr(E_1\cap E_2) = 2/8 = 1/4$, which is equal to $\pr(E_1)\pr(E_2) = 1/4$. $E_1, E_2$ are independent. 
		\item[\textbf{(b)}] $E_1=\{\text{THH, THT, TTH, TTT}\}$, and $E_2=\{\text{HHT, THH}\}$. Thus $\pr(E_1) = 1/2$, $\pr(E_2) = 1/4$. Since $E_1 \cap E_2 = \{\text{THH}\}$, $\pr(E_1\cap E_2) = 1/8$, which is equal to $\pr(E_1)\pr(E_2)=1/8$. $E_1, E_2$ are independent.
		\item[\textbf{(c)}] $E_1 = \{\text{HTH, HTT, TTH, TTT}\}$, and $E_2=\{\text{HHT, THH}\}$. Thus $\pr(E_1) = 1/2$, $\pr(E_2) = 1/4$. Since $E_1 \cap E_2 = \varnothing$, $\pr(E_1\cap E_2) \neq \pr(E_1)\pr(E_2)$. Thus $E_1, E_2$ are dependent. 
	\end{itemize} \qed
	
\item[\large \textbf{7.2.24}] Let
	$$A: \text{First flip comes up tails when a fair coin is flipped 5 times.}$$
	$$B: \text{Exactly 4 heads appear when a fair coin is flipped 5 times.}$$
	We want to calculate $\pr(B\:|\:A)$.\\
	$\pr(A) = 1/2$ since we only care about the outputs of the first flip, and $\pr(A\cap B) = 1/32$ since THHHH is the only possible case. From the definition, $\pr(B\:|\:A) = {\pr(A\cap B)}/{\pr(A)} = 1/16$. \qed
	
\item[\large \textbf{7.2.34}] The probability of success is $p$, and failure is $1-p$.
	\begin{itemize}
		\item[\textbf{(a)}] Fails for $n$ times. Thus $(1-p)^n$.
		\item[\textbf{(b)}] Since $1 = \pr(\text{No successes}) + \pr(\text{At least 1 success})$, the wanted probability is $1-(1-p)^n$.
		\item[\textbf{(c)}] For the case $n = 0$, it is trivial that the answer is $1$. For $n> 0$, the only possible cases are: No successes, and only 1 success. The probability of 1 success is $np(1-p)^{n-1}$ since we fail for $n-1$ times and succeed once, and we can succeed on any $n$ trials, out of $n$ trials. Thus the wanted probability is: $(1-p)^n + np(1-p)^{n-1}$. 
		\item[\textbf{(d)}] For the case $n = 0$, it is trivial that the answer is $0$. For $n> 0$, since $1 = \pr(\text{At most 1 success}) + \pr(\text{At least 2 successes})$, the wanted probability is equal to $1 -$ (answer of \textbf{(c)}). Thus the wanted probability is $1-\left[(1-p)^n + np(1-p)^{n-1}\right]$.
	\end{itemize} \qed
\item[\large \textbf{7.3.14}] From Bayes' theorem,
$$
\begin{aligned}
	\pr(F_2 | E) &= \frac{\pr(E\cap F_2)}{\pr(E)} = \frac{\pr(E | F_2)\pr(F_2)}{\pr(E \cap F_1) + \pr(E \cap F_2) + \pr(E \cap F_3)} \\
	 &= \frac{\pr(E | F_2)\pr(F_2)}{\pr(E | F_1)\pr(F_1) + \pr(E | F_2)\pr(F_2) + \pr(E | F_3)\pr(F_3)} \\
	 &= \frac{{3}/{8}\cdot {1}/{2}}{{2}/{7}\cdot{1}/{6} + {3}/{8}\cdot{1}/{2} + {1}/{2}\cdot{1}/{3}} = \frac{7}{15}
\end{aligned}
$$\qed

\item[\large \textbf{7.3.22}] 
	\begin{itemize}
		\item[\textbf{(a)}] We can estimate that $\pr(S) = s/(s+h)$, and $\pr(\bar{S}) = h/(s+h)$.
		\item[\textbf{(b)}] Let $W$ be the event that an incoming message contains the word $w$. We want to calculate $\pr(S \: |\:W)$. By Bayes' theorem,
		$$
		\begin{aligned}
		\pr(S \: |\:W) &= \frac{\pr(S \cap W)}{\pr(W)} = \frac{\pr(W \: | \:S)\pr(S)}{\pr(W\cap S) + \pr(W\cap \bar{S})} = \frac{\pr(W \: | \:S)\pr(S)}{\pr(W \: | \:S)\pr(S) + \pr(W \: | \:\bar{S})\pr(\bar{S})}\\
		&=\frac{p(w)\cdot \dfrac{s}{s+h}}{p(w) \cdot\dfrac{s}{s+h} + q(w) \cdot\dfrac{h}{s+h}} = \frac{sp(w)}{sp(w) + hq(w)}
		\end{aligned}
		$$
	\end{itemize} \qed
\item[\large \textbf{7.4.18}] Using that $X, Y$ are non-negative and by the definition of $Z$, $Z(s) \leq X(s)+Y(s)$. Thus,
$$\ex(Z) = \sum_{s\in S} Z(s) \pr(s) \leq \sum_{s \in S} (X(s)+Y(s))\pr(s) = \sum_{s \in S} X(s)\pr(s) + \sum_{s \in S} Y(s)\pr(s) = \ex(X)+\ex(Y)$$ \qed

\item[\large \textbf{7.4.38}]
	\begin{itemize}
		\item[\textbf{(a)}] Let $X$ be the number of cans filled on a day. By Markov's inequality, $$\pr(X > 11000) < \frac{\ex(X)}{11000} = \frac{10000}{11000} = \frac{10}{11}$$
		\item[\textbf{(b)}] By Chebyshev's inequality, $$
		\begin{aligned}
		\pr(9000<X<11000) &= \pr(\left|X - \ex(X)\right| < 1000) = 1 - \pr(\left|X - \ex(X)\right| \geq 1000) \\
		&\geq 1 - \frac{\var(X)}{1000^2} = \frac{999}{1000}
		\end{aligned}$$
	\end{itemize} \qed
\item[\large \textbf{7.4.48}] Define a random variable $X_i$ as follows.
$$X_i = \begin{cases}
\: 1 & \text{if } i\text{-th ball is in the first bin}\\
\: 0 & \text{otherwise}
		\end{cases}$$
And define $X = \sum_{i=1}^m X_i$. Then the expected number of balls that fall into the first bin is $\ex(X)$. By the linearity of expectation, $\ex(X)=\sum_{i=1}^m \ex(X_i)$. Now we calculate $\ex(X_i)$. \\
By definition, $\ex(X_i) = 1 \cdot \pr(X_i = 1) + 0 \cdot \pr(X_i = 0) = 1/n$. (Clearly $\pr(X_i = 1) = 1/n$, and this situation is symmetric for all $i$). Thus the expected number of balls in the first bin is $m/n$. \qed





\end{itemize}
\end{document}