\section*{May 15th, 2019}
\textbf{4.2 Mean Value Theorem}\\
\textbf{Lemma 4.2.1} \textbf{(Rolle's Theorem)} Suppose $f:[a, b]\ra \R$ is continuous on $[a, b]$ and differentiable on $(a, b)$. If $f(a) = f(b)$, there exists $c \in (a, b)$ s.t. $f'(c) = 0$.\\
\pf.
\begin{enumerate}
	\item Maximum of $f = $ Minimum of $f =f(a) = f(b)$ \\
	$f$ is constant. Trivial.
	\item Maximum of $f$ is not $f(a), f(b)$\\
	Suppose $f$ attains maximum at $x = c \in (a, b)$ Then $f'(c) = \ds\lim_{h\ra 0}\frac{f(c+h)-f(c)}{h}$ must be 0. ($\because f'_+(c) \leq 0$ and $f'_-(c) \geq 0$)
	\item Minimum of $f$ is not $f(a), f(b)$\\
	(Proof is identical to that of (2))
\end{enumerate}~\\
\thm{ 4.2.2} \textbf{(Cauchy's Mean Value Theorem)} Suppose $f, g:[a, b]\ra \R$ are continuous on $[a, b]$ and differentiable on $(a, b)$. Then there exists $c\in (a, b)$ s.t. $$(g(a) - g(b))f'(c) = (f(a) - f(b))g'(c)$$
\pf. Set $h(x) = (g(a) - g(b))f(x) - (f(a)-f(b))g(x)$ and apply Rolle's Thm.\\
\\
\thm{ 4.2.3} \textbf{(Mean Value Theorem)} Suppose $f :[a, b]\ra \R$ is continuous on $[a, b]$ and differentiable on $(a, b)$. Then there exists $c\in (a, b)$ s.t. $$f'(c) = \frac{f(b)-f(a)}{b - a}$$
\pf. Set $g(x) = x$ in Cauchy's MVT.\\
\\
\thm{ 4.2.5} \textbf{(L'Hopital's Rule)} Suppose $f, g:(a, b)\ra \R$ are differentiable on $(a, b)$. For $x_0\in (a, b)$, if $f(x_0) = g(x_0) = 0$ and $\ds\lim_{x\ra x_0} \frac{f'(x)}{g'(x)} = \alpha$, then $\ds\lim_{x\ra x_0}\frac{f(x)}{g(x)}=\alpha$.\\
\pf. Given $\epsilon > 0$, there exists $\delta > 0$ s.t. if $\abs{x - x_0} < \delta$ then $\abs{f'(x) / g'(x) - \alpha} < \epsilon$.\\ By Cauchy's MVT, there exists $c_x$ in between $x_0$ and $x$ s.t. $$\frac{f(x)}{g(x)} = \frac{f(x) - f(x_0)}{g(x) - g(x_0)} = \frac{f'(c_x)}{g'(c_x)}$$
If $\abs{x - x_0} < \delta$, 
$$\abs{\frac{f(x)}{g(x)} - \alpha} = \abs{\frac{f'(c_x)}{g'(c_x)} - \alpha} < \epsilon$$
since $\abs{c_x - x_0} < \abs{x - x_0} < \delta$.\\
\\
\textbf{4.3 Taylor Expansion}\\
Suppose $I$ is a closed interval, and $a\in I$.\\
\\
\thm{ 4.3.1} Suppose $f, g:I\ra \R \in C^\infty(I)$. If $x\in \inte (I)$, there exists $c_x$ between $a$ and $x$ s.t. $$ \left(f(x) - \sum_{k =0}^n \frac{f^{(k)}(a)}{k!}(x-a)^k\right)g^{(n+1)}(c_x) = \left(g(x) - \sum_{k =0}^n \frac{g^{(k)}(a)}{k!}(x-a)^k\right)f^{(n+1)}(c_x)$$
\\
\pf. Fix $x$. Define $$F(t) = \sum_{k =0}^n \frac{f^{(k)}(t)}{k!}(x-t)^k$$
Then\footnote{Note the $k=1$ in the second term.} $$F'(t) = \sum_{k =0}^n \frac{f^{(k+1)}(t)}{k!}(x-t)^k + \sum_{k =1}^n \frac{f^{(k)}(t)}{k!}(-1)^k(x-t)^{k-1} = \frac{f^{(n+1)}(t)}{n!}(x-t)^n$$
Similarly define $G(t)$ and calculate $G'(t) = g^{(n+1)}(t) / n! \cdot (x-t)^n$.\\
By Cauchy's MVT, there exists $c_x$ between $a$ and $x$ s.t. $$(F(x) - F(a))G'(c_x) = (G(x) - G(a))F'(c_x)$$
which simplifies to $$(f(x) - F(a))g^{(n+1)}(c_x)\frac{(x-c_x)^n}{n!} = (g(x) - G(a))f^{(n+1)}(c_x)\frac{(x-c_x)^n}{n!}$$
and now the result directly follows.\\
\\
\rmk.
\begin{enumerate}
	\item Taylor Expansion (around $a$)
	$$f(x) = \sum_{k=0}^\infty \frac{f^{(k)}(a)}{k!}(x-a)^k$$
	\item (In the book) $f, g \in C^n(I)$, and $f^{(n)}, g^{(n)}$ should be differentiable on $\inte(I)$. 
	\item \textbf{(Taylor's Theorem)} Set $g(x) = (x-a)^{n+1}$. $g^{(0)}(a) = \cdots = g^{(n)}(a) =0$, but $g^{(n+1)}(x) = (n+1)! $ (constant). Then we have 
	$$f(x) - \sum_{k =0}^n \frac{f^{(k)}(a)}{k!}(x-a)^k = f^{(n+1)}(c_x) \frac{(x-a)^{n+1}}{(n+1)!}$$
\end{enumerate}~\\
\prop{ 4.3.3} Suppose $f:I\ra \R \in C^{\infty}(I)$.\footnote{Such functions are called \textbf{smooth}.} For $a, x\in I$, define $J$ as a interval with $a, x$ as two endpoints. If there exists $M > 0$ s.t. $\abs{f^{(n)}(y)} \leq M$ for $\forall n\in \N, \forall y\in J$,\footnote{이 조건은 매우 \textbf{과한} 조건이다.} then $$f(x) = \sum_{k=0}^\infty \frac{f^{(k)}(a)}{k!}(x-a)^k$$
\pf. Define $$S_n(x) = \sum_{k=0}^n \frac{f^{(k)}(a)}{k!}(x-a)^k$$
then we want to show that $\ds \lim_{n\ra\infty} \abs{S_n(x) - f(x)} = 0$.\\
By Taylor's Theorem, $\exists\,c_x \in J$ s.t. $$\abs{f(x) - S_n(x)} \leq \abs{f^{(n+1)}(c_x)}\frac{\abs{x-a}^{n+1}}{(n+1)!} \leq M \frac{\abs{x-a}^{n+1}}{(n+1)!} \ra 0$$
The last term converges to $0$ since factorials increase faster than exponents.\\
\\
\ex. $f(x) = \sin x$ satisfies the conditions of Prop 4.3.3, and calculating $f^{(k)}(0)$ gives $$\sin x = \sum_{k=0}^\infty \frac{(-1)^k}{(2k+1)!}x^{2k+1}$$
\ex. $f(x) = e^x$, at $a = 0$. $x\in \R_{\geq 0}$, $\{f^{(n)}(t):t\in [0, x], n\in \N \}$ is bounded by $e^x$. Thus $f(x) = \sum_{k =0}^\infty x^k/k!$ $ (x\geq0)$

\pagebreak